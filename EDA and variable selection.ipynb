{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import calendar\n",
    "import datetime\n",
    "os.getcwd()\n",
    "os.chdir('D:/Desktop/Flex 3/Grad Case Study/Data/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACCT_BAL = 47828339 ~ 47.8 million total rows = 40022484 ~ 40 million filtered rows\n",
    "#TRAN_sum = 42624951 ~ 42.6 million total rows = 31769701 ~ 31.7 million filtered rows\n",
    "#HH_sum = 77173079 ~ 77.2 million total rows = 32584691  ~ 32.6 million filtered rows\n",
    "#CUST_sum = 98118047 ~ 98.1 million total rows = 37871352 ~ 37.9 million filtered rows\n",
    "\n",
    "#ACCT_BAL = 3873981 ~ 3.9 million unique keys (I_REC_KEY)   \n",
    "#TRAN_sum = 4278082 ~ 4.3 million unique rows (I_REC_KEY, ACCT_KEY)\n",
    "#HH_sum = 6115024 ~ 6.1 million unique keys (HH_KEY)\n",
    "#cust_sum = 8794824 ~ 8.8 million unique keys (CUST_KEY)\n",
    "#HH_sum = 5648857 ~ 5.65 million filtered unique keys (HH_KEY)\n",
    "#REF table unique_keys = 3214696 ~ 3.2 million"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter only Checking products from accounts summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I_REC_KEY</th>\n",
       "      <th>DATE_KEY</th>\n",
       "      <th>AVG_MONTHLY_BAL_AMT</th>\n",
       "      <th>LAST_STMT_BAL_AMT</th>\n",
       "      <th>MRKTG_PROD_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8923024</td>\n",
       "      <td>31OCT2018</td>\n",
       "      <td>2653.0</td>\n",
       "      <td>2487.0</td>\n",
       "      <td>REGULAR BUS CHECKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8923024</td>\n",
       "      <td>31DEC2018</td>\n",
       "      <td>2794.0</td>\n",
       "      <td>4160.0</td>\n",
       "      <td>REGULAR BUS CHECKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8923024</td>\n",
       "      <td>30NOV2018</td>\n",
       "      <td>2578.0</td>\n",
       "      <td>3626.0</td>\n",
       "      <td>REGULAR BUS CHECKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8923024</td>\n",
       "      <td>31JAN2019</td>\n",
       "      <td>2332.0</td>\n",
       "      <td>2374.0</td>\n",
       "      <td>REGULAR BUS CHECKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8923024</td>\n",
       "      <td>28FEB2019</td>\n",
       "      <td>2357.0</td>\n",
       "      <td>2648.0</td>\n",
       "      <td>REGULAR BUS CHECKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47828334</td>\n",
       "      <td>159358854</td>\n",
       "      <td>31DEC2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5/3 FREE CHECKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47828335</td>\n",
       "      <td>159358693</td>\n",
       "      <td>31DEC2019</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5/3 FREE CHECKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47828336</td>\n",
       "      <td>159358870</td>\n",
       "      <td>31DEC2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5/3 FREE CHECKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47828337</td>\n",
       "      <td>159358595</td>\n",
       "      <td>31DEC2019</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ENHANCED CHECKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47828338</td>\n",
       "      <td>159358760</td>\n",
       "      <td>31DEC2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5/3 FREE CHECKING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47828339 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          I_REC_KEY   DATE_KEY  AVG_MONTHLY_BAL_AMT  LAST_STMT_BAL_AMT  \\\n",
       "0           8923024  31OCT2018               2653.0             2487.0   \n",
       "1           8923024  31DEC2018               2794.0             4160.0   \n",
       "2           8923024  30NOV2018               2578.0             3626.0   \n",
       "3           8923024  31JAN2019               2332.0             2374.0   \n",
       "4           8923024  28FEB2019               2357.0             2648.0   \n",
       "...             ...        ...                  ...                ...   \n",
       "47828334  159358854  31DEC2019                  0.0                0.0   \n",
       "47828335  159358693  31DEC2019                 16.0                0.0   \n",
       "47828336  159358870  31DEC2019                  0.0                0.0   \n",
       "47828337  159358595  31DEC2019                661.0                0.0   \n",
       "47828338  159358760  31DEC2019                  0.0                0.0   \n",
       "\n",
       "               MRKTG_PROD_NAME  \n",
       "0         REGULAR BUS CHECKING  \n",
       "1         REGULAR BUS CHECKING  \n",
       "2         REGULAR BUS CHECKING  \n",
       "3         REGULAR BUS CHECKING  \n",
       "4         REGULAR BUS CHECKING  \n",
       "...                        ...  \n",
       "47828334     5/3 FREE CHECKING  \n",
       "47828335     5/3 FREE CHECKING  \n",
       "47828336     5/3 FREE CHECKING  \n",
       "47828337     ENHANCED CHECKING  \n",
       "47828338     5/3 FREE CHECKING  \n",
       "\n",
       "[47828339 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading Account Balance file\n",
    "ACCT_BAL=pd.read_csv('/UC_CoBA_NJB/UC_CoBA_ACCT_BAL_MONTHLY_15.txt', header=0,sep='|')\n",
    "ACCT_BAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count number of unique products\n",
    "ACCT_BAL.MRKTG_PROD_NAME.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save unique products\n",
    "checking_account=pd.DataFrame(ACCT_BAL.MRKTG_PROD_NAME.unique())\n",
    "#checking_account.to_csv(\"identify_checking_accounts.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter only Checking accounts\n",
    "checking_prod=[\"CHECKING\",\"CKG\",\"CHKNG\",\"CHKG\"]\n",
    "ACCT_prod_filtered=ACCT_BAL[ACCT_BAL['MRKTG_PROD_NAME'].str.contains('|'.join(checking_prod))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross check number of filtered checking accounts\n",
    "ACCT_prod_filtered.MRKTG_PROD_NAME.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store unique products as list\n",
    "acct_prod_unique_keys=ACCT_prod_filtered['I_REC_KEY'].unique().tolist()\n",
    "#1)End of Product filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter 'Retail', 'Consumer' from Household summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading HH file\n",
    "HH_sum_table=pd.read_csv('UC_CoBA_HH_SUMM_MONTHLY_15.txt', header=0,sep='|',usecols=['HH_KEY','HH_SEG_CODE','HH_TYPE_CODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Retail Consumer and convert it to list\n",
    "HH_seg_unique_keys=['R']\n",
    "HH_type_unique_keys=['C']\n",
    "HH_seg_filtered=HH_sum_table[HH_sum_table['HH_TYPE_CODE'].isin(HH_type_unique_keys)]\n",
    "HH_seg_type_filtered=HH_seg_filtered[HH_seg_filtered['HH_SEG_CODE'].isin(HH_seg_unique_keys)]\n",
    "HH_filtered_keys=HH_seg_type_filtered['HH_KEY'].unique().tolist()\n",
    "#1)End of HH Seg filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter the Reference file by 'Retail', 'Consumer' with Checking Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I_REC_KEY</th>\n",
       "      <th>ACCT_KEY</th>\n",
       "      <th>CURR_CUST_KEY</th>\n",
       "      <th>CURR_HH_KEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39155074</td>\n",
       "      <td>16110071</td>\n",
       "      <td>32777172.0</td>\n",
       "      <td>6520155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14005888</td>\n",
       "      <td>16256538</td>\n",
       "      <td>34896115.0</td>\n",
       "      <td>3407771.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>131963766</td>\n",
       "      <td>17317526</td>\n",
       "      <td>20040290.0</td>\n",
       "      <td>6593223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10190016</td>\n",
       "      <td>16298146</td>\n",
       "      <td>33908034.0</td>\n",
       "      <td>964223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>131777109</td>\n",
       "      <td>17303491</td>\n",
       "      <td>61578406.0</td>\n",
       "      <td>6523463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20935733</td>\n",
       "      <td>133409944</td>\n",
       "      <td>70594128</td>\n",
       "      <td>19320352.0</td>\n",
       "      <td>12918952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20935734</td>\n",
       "      <td>13227827</td>\n",
       "      <td>9098557</td>\n",
       "      <td>24558970.0</td>\n",
       "      <td>4093352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20935735</td>\n",
       "      <td>155309730</td>\n",
       "      <td>80500877</td>\n",
       "      <td>69230532.0</td>\n",
       "      <td>75736723.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20935736</td>\n",
       "      <td>135209687</td>\n",
       "      <td>71924766</td>\n",
       "      <td>19320749.0</td>\n",
       "      <td>13574886.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20935737</td>\n",
       "      <td>13314721</td>\n",
       "      <td>9108270</td>\n",
       "      <td>31858239.0</td>\n",
       "      <td>4328551.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20935738 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          I_REC_KEY  ACCT_KEY  CURR_CUST_KEY  CURR_HH_KEY\n",
       "0          39155074  16110071     32777172.0    6520155.0\n",
       "1          14005888  16256538     34896115.0    3407771.0\n",
       "2         131963766  17317526     20040290.0    6593223.0\n",
       "3          10190016  16298146     33908034.0     964223.0\n",
       "4         131777109  17303491     61578406.0    6523463.0\n",
       "...             ...       ...            ...          ...\n",
       "20935733  133409944  70594128     19320352.0   12918952.0\n",
       "20935734   13227827   9098557     24558970.0    4093352.0\n",
       "20935735  155309730  80500877     69230532.0   75736723.0\n",
       "20935736  135209687  71924766     19320749.0   13574886.0\n",
       "20935737   13314721   9108270     31858239.0    4328551.0\n",
       "\n",
       "[20935738 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the Reference file\n",
    "CUST_HH_REF=pd.read_csv('UC_CoBA_ACCT_CUST_HH_XREF.txt', header=0,sep='|')\n",
    "CUST_HH_REF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the Ref file by 1) Products\n",
    "ref_prod_filtered=CUST_HH_REF[CUST_HH_REF['I_REC_KEY'].isin(acct_prod_unique_keys)]\n",
    "ref_prod_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Filter the Ref file by 2) HH Segments\n",
    "REF_prod_seg_filtered=ref_prod_filtered[ref_prod_filtered['CURR_HH_KEY'].isin(HH_filtered_keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, count the number of unique accounts filtered\n",
    "REF_prod_seg_filtered['ACCT_KEY'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I_REC_KEY</th>\n",
       "      <th>ACCT_KEY</th>\n",
       "      <th>CURR_CUST_KEY</th>\n",
       "      <th>CURR_HH_KEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>13970302</td>\n",
       "      <td>16198496</td>\n",
       "      <td>33452982.0</td>\n",
       "      <td>3552900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>13095040</td>\n",
       "      <td>16217550</td>\n",
       "      <td>59936676.0</td>\n",
       "      <td>3932333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>12861899</td>\n",
       "      <td>16248733</td>\n",
       "      <td>60770157.0</td>\n",
       "      <td>4026773.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>14326125</td>\n",
       "      <td>16249054</td>\n",
       "      <td>32359271.0</td>\n",
       "      <td>3792490.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>14354993</td>\n",
       "      <td>16306848</td>\n",
       "      <td>23563952.0</td>\n",
       "      <td>8071512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20935072</td>\n",
       "      <td>66785729</td>\n",
       "      <td>42186935</td>\n",
       "      <td>19285086.0</td>\n",
       "      <td>15400972.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20935073</td>\n",
       "      <td>9720987</td>\n",
       "      <td>1895448</td>\n",
       "      <td>19287980.0</td>\n",
       "      <td>73982670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20935074</td>\n",
       "      <td>97548809</td>\n",
       "      <td>56591739</td>\n",
       "      <td>19291002.0</td>\n",
       "      <td>76036060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20935079</td>\n",
       "      <td>14694198</td>\n",
       "      <td>17039189</td>\n",
       "      <td>19280620.0</td>\n",
       "      <td>3608967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20935535</td>\n",
       "      <td>20573476</td>\n",
       "      <td>20434368</td>\n",
       "      <td>19274721.0</td>\n",
       "      <td>630306.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3214771 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          I_REC_KEY  ACCT_KEY  CURR_CUST_KEY  CURR_HH_KEY\n",
       "5          13970302  16198496     33452982.0    3552900.0\n",
       "6          13095040  16217550     59936676.0    3932333.0\n",
       "7          12861899  16248733     60770157.0    4026773.0\n",
       "8          14326125  16249054     32359271.0    3792490.0\n",
       "10         14354993  16306848     23563952.0    8071512.0\n",
       "...             ...       ...            ...          ...\n",
       "20935072   66785729  42186935     19285086.0   15400972.0\n",
       "20935073    9720987   1895448     19287980.0   73982670.0\n",
       "20935074   97548809  56591739     19291002.0   76036060.0\n",
       "20935079   14694198  17039189     19280620.0    3608967.0\n",
       "20935535   20573476  20434368     19274721.0     630306.0\n",
       "\n",
       "[3214771 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save the file\n",
    "REF_prod_seg_filtered.to_csv(\"final_filtered_keys.csv\", index=False, header=True)\n",
    "REF_prod_seg_filtered.to_csv(\"final_filtered_keys.txt\", index=False, header=True)\n",
    "REF_prod_seg_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Code is to get last dates of observation for a account and then to create targets (Customer likely to churn). Any account which is not present in the last date of the data files are flagged to abe attrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark Attrite customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = pd.read_csv('final_filtered_keys.csv')\n",
    "keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing number of keys into 3 parts (30%, 35%, 35%) 964431+1125170+1125170\n",
    "keys_new = keys.sample(frac=0.3)\n",
    "keys_new_rest = keys[~keys.index.isin(keys_new.index)]\n",
    "keys_new_rest1 = keys_new_rest.sample(frac=0.5)\n",
    "keys_new_rest2 = keys_new_rest[~keys_new_rest.index.isin(keys_new_rest1.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accts = pd.read_table('UC_CoBA_ACCT_BAL_MONTHLY_15.txt', usecols= ['I_REC_KEY','DATE_KEY'] ,sep=\"|\")\n",
    "accts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_file1 = pd.merge(accts, \n",
    "                  keys_new,\n",
    "                  left_on='I_REC_KEY',\n",
    "                  right_on='I_REC_KEY',\n",
    "                  how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_file2 = pd.merge(accts, \n",
    "                  keys_new_rest1,\n",
    "                  left_on='I_REC_KEY',\n",
    "                  right_on='I_REC_KEY',\n",
    "                  how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_file3 = pd.merge(accts, \n",
    "                  keys_new_rest2,\n",
    "                  left_on='I_REC_KEY',\n",
    "                  right_on='I_REC_KEY',\n",
    "                  how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format = \"%d%b%Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_file1 = joined_file1.drop(columns=['ACCT_KEY','CURR_CUST_KEY','CURR_HH_KEY'], axis=1)\n",
    "joined_file2 = joined_file2.drop(columns=['ACCT_KEY','CURR_CUST_KEY','CURR_HH_KEY'], axis=1)\n",
    "joined_file3 = joined_file3.drop(columns=['ACCT_KEY','CURR_CUST_KEY','CURR_HH_KEY'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Below codes in the sequence mentioned in comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_file1['newdate'] = [datetime.datetime.strptime(d, date_format) for d in joined_file1[\"DATE_KEY\"]] # Run1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_file2['newdate'] = [datetime.datetime.strptime(d, date_format) for d in joined_file2[\"DATE_KEY\"]] # Run4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_file3['newdate'] = [datetime.datetime.strptime(d, date_format) for d in joined_file3[\"DATE_KEY\"]] # Run7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_acct1 = joined_file1.groupby(['I_REC_KEY']).apply(pd.DataFrame.sort_values, 'newdate') # Run2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_acct2 = joined_file2.groupby(['I_REC_KEY']).apply(pd.DataFrame.sort_values, 'newdate') #Run5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_acct3 = joined_file3.groupby(['I_REC_KEY']).apply(pd.DataFrame.sort_values, 'newdate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date1 = grouped_acct1.groupby(['I_REC_KEY']).last() # Run3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date2 = grouped_acct2.groupby(['I_REC_KEY']).last() # Run6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date3 = grouped_acct3.groupby(['I_REC_KEY']).last() #Run8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag1 = [] \n",
    "for value in last_date1[\"DATE_KEY\"]: \n",
    "    if value == \"31DEC2019\": \n",
    "        flag1.append(0) \n",
    "    else: \n",
    "        flag1.append(1)\n",
    "\n",
    "last_date1[\"flag\"] = flag1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag2 = [] \n",
    "for value in last_date2[\"DATE_KEY\"]: \n",
    "    if value == \"31DEC2019\": \n",
    "        flag2.append(0) \n",
    "    else: \n",
    "        flag2.append(1)\n",
    "\n",
    "last_date2[\"flag\"] = flag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag3 = [] \n",
    "for value in last_date1[\"DATE_KEY\"]: \n",
    "    if value == \"31DEC2019\": \n",
    "        flag3.append(0) \n",
    "    else: \n",
    "        flag3.append(1)\n",
    "\n",
    "last_date3[\"flag\"] = flag3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date = last_date1.append(last_date2)\n",
    "last_date = last_date.append(last_date3)\n",
    "last_date = last_date.rename(columns={\"DATE_KEY\":\"lastdate\",\"newdate\":\"lastdateindate\",\"flag\":\"attritionflag\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date.to_csv('attritionflags.csv') # Should have (3214771, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Target Flag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accts.DATE_KEY.unique()\n",
    "accts.shape, accts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_flag = pd.read_csv('attritionflags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load accts and attrition flag file before \n",
    "\n",
    "def target_func2(for_month,months,rate):         ### rate =1 for target rate , rate anything other than 1 will output the file\n",
    "    acct = accts[accts['DATE_KEY']== for_month]\n",
    "    \n",
    "    for_date = datetime.datetime.strptime(for_month, date_format)\n",
    "    month = for_date.month\n",
    "    file_month = month\n",
    "    year = for_date.year + month // 12\n",
    "    month = month % 12 + 1\n",
    "    day = max(1, calendar.monthrange(year,month)[1])\n",
    "    \n",
    "    last_month = datetime.datetime(year,month,day,0,0,0)\n",
    "    last_month = last_month.strftime('%d%b%Y').upper()\n",
    "    \n",
    "    attrition = attrition_flag[attrition_flag['attritionflag']==1]\n",
    "    attrition = attrition[attrition['lastdate']==last_month]\n",
    "    file = pd.merge(acct,\n",
    "                   attrition,\n",
    "                   left_on = 'I_REC_KEY',\n",
    "                   right_on = 'I_REC_KEY',\n",
    "                   how = 'left')\n",
    "    target = [] \n",
    "    for value in file[\"attritionflag\"]: \n",
    "        if value == 1: \n",
    "            target.append(1) \n",
    "        else: \n",
    "            target.append(0) \n",
    "    file['target']=target\n",
    "    file['month']=file_month\n",
    "    file = file.drop(columns=['lastdate','lastdateindate','attritionflag'],axis=1)\n",
    "    \n",
    "    target_rate = file[file['target']==1].shape[0]/file.shape[0]\n",
    "    if rate == 1: \n",
    "        return target_rate \n",
    "    else: \n",
    "        return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nov_file = target_func2('30NOV2018',1,0)\n",
    "dec_file = target_func2('31DEC2018',1,0)\n",
    "jan_file = target_func2('31JAN2019',1,0)\n",
    "feb_file = target_func2('28FEB2019',1,0)\n",
    "mar_file = target_func2('31MAR2019',1,0)\n",
    "apr_file = target_func2('30APR2019',1,0)\n",
    "may_file = target_func2('31MAY2019',1,0)\n",
    "jun_file = target_func2('30JUN2019',1,0)\n",
    "jul_file = target_func2('31JUL2019',1,0)\n",
    "aug_file = target_func2('31AUG2019',1,0)\n",
    "sep_file = target_func2('30SEP2019',1,0)\n",
    "oct_file = target_func2('31OCT2019',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nov_file.append([dec_file, jan_file,feb_file,mar_file,apr_file,may_file,jun_file,jul_file,aug_file,sep_file,oct_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sampling and building final dataframe\n",
    "\n",
    "final_df = pd.DataFrame(columns=['I_REC_KEY','DATE_KEY','target','month'])\n",
    "\n",
    "for i in range(1,13):\n",
    "    if i == 1:\n",
    "        sam_key = (df[df['month']==i]).sample(250000)\n",
    "        final_df = final_df.append(sam_key)\n",
    "    else:\n",
    "        df_temp = df[df['month']==i]\n",
    "        sam_key = df_temp[~df_temp.I_REC_KEY.isin(final_df['I_REC_KEY'])].sample(250000)\n",
    "        final_df = final_df.append(sam_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('Finaldata_4_EDA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data is prepared for EDA now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "This Code is to get last dates of observation for a account and then to create targets (Customer likely to churn). Any account which is not present in the last date of the data files are flagged to abe attrite\n",
    "\n",
    "### Mark Attrite customers\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import calendar\n",
    "import datetime\n",
    "os.getcwd()\n",
    "os.chdir('D:\\Cincinnati\\Classes\\9. Graduate Case studies')\n",
    "os.getcwd()\n",
    "\n",
    "keys = pd.read_csv('final_filtered_keys.csv')\n",
    "keys.shape\n",
    "\n",
    "# Dividing number of keys into 3 parts (30%, 35%, 35%) 964431+1125170+1125170\n",
    "keys_new = keys.sample(frac=0.3)\n",
    "keys_new_rest = keys[~keys.index.isin(keys_new.index)]\n",
    "keys_new_rest1 = keys_new_rest.sample(frac=0.5)\n",
    "keys_new_rest2 = keys_new_rest[~keys_new_rest.index.isin(keys_new_rest1.index)]\n",
    "\n",
    "accts = pd.read_table('UC_CoBA_ACCT_BAL_MONTHLY_15.txt', usecols= ['I_REC_KEY','DATE_KEY'] ,sep=\"|\")\n",
    "accts.shape\n",
    "\n",
    "joined_file1 = pd.merge(accts, \n",
    "                  keys_new,\n",
    "                  left_on='I_REC_KEY',\n",
    "                  right_on='I_REC_KEY',\n",
    "                  how='inner')\n",
    "\n",
    "joined_file2 = pd.merge(accts, \n",
    "                  keys_new_rest1,\n",
    "                  left_on='I_REC_KEY',\n",
    "                  right_on='I_REC_KEY',\n",
    "                  how='inner')\n",
    "\n",
    "joined_file3 = pd.merge(accts, \n",
    "                  keys_new_rest2,\n",
    "                  left_on='I_REC_KEY',\n",
    "                  right_on='I_REC_KEY',\n",
    "                  how='inner')\n",
    "\n",
    "date_format = \"%d%b%Y\"\n",
    "\n",
    "joined_file1 = joined_file1.drop(columns=['ACCT_KEY','CURR_CUST_KEY','CURR_HH_KEY'], axis=1)\n",
    "joined_file2 = joined_file2.drop(columns=['ACCT_KEY','CURR_CUST_KEY','CURR_HH_KEY'], axis=1)\n",
    "joined_file3 = joined_file3.drop(columns=['ACCT_KEY','CURR_CUST_KEY','CURR_HH_KEY'], axis=1)\n",
    "\n",
    "Run Below codes in the sequence mentioned in comments \n",
    "\n",
    "joined_file1['newdate'] = [datetime.datetime.strptime(d, date_format) for d in joined_file1[\"DATE_KEY\"]] # Run1 \n",
    "\n",
    "joined_file2['newdate'] = [datetime.datetime.strptime(d, date_format) for d in joined_file2[\"DATE_KEY\"]] # Run4\n",
    "\n",
    "joined_file3['newdate'] = [datetime.datetime.strptime(d, date_format) for d in joined_file3[\"DATE_KEY\"]] # Run7\n",
    "\n",
    "grouped_acct1 = joined_file1.groupby(['I_REC_KEY']).apply(pd.DataFrame.sort_values, 'newdate') # Run2\n",
    "\n",
    "grouped_acct2 = joined_file2.groupby(['I_REC_KEY']).apply(pd.DataFrame.sort_values, 'newdate') #Run5\n",
    "\n",
    "grouped_acct3 = joined_file3.groupby(['I_REC_KEY']).apply(pd.DataFrame.sort_values, 'newdate')\n",
    "\n",
    "last_date1 = grouped_acct1.groupby(['I_REC_KEY']).last() # Run3\n",
    "\n",
    "last_date2 = grouped_acct2.groupby(['I_REC_KEY']).last() # Run6\n",
    "\n",
    "last_date3 = grouped_acct3.groupby(['I_REC_KEY']).last() #Run8 \n",
    "\n",
    "flag1 = [] \n",
    "for value in last_date1[\"DATE_KEY\"]: \n",
    "    if value == \"31DEC2019\": \n",
    "        flag1.append(0) \n",
    "    else: \n",
    "        flag1.append(1)\n",
    "\n",
    "last_date1[\"flag\"] = flag1   \n",
    "\n",
    "flag2 = [] \n",
    "for value in last_date2[\"DATE_KEY\"]: \n",
    "    if value == \"31DEC2019\": \n",
    "        flag2.append(0) \n",
    "    else: \n",
    "        flag2.append(1)\n",
    "\n",
    "last_date2[\"flag\"] = flag2\n",
    "\n",
    "flag3 = [] \n",
    "for value in last_date1[\"DATE_KEY\"]: \n",
    "    if value == \"31DEC2019\": \n",
    "        flag3.append(0) \n",
    "    else: \n",
    "        flag3.append(1)\n",
    "\n",
    "last_date3[\"flag\"] = flag3\n",
    "\n",
    "last_date = last_date1.append(last_date2)\n",
    "last_date = last_date.append(last_date3)\n",
    "last_date = last_date.rename(columns={\"DATE_KEY\":\"lastdate\",\"newdate\":\"lastdateindate\",\"flag\":\"attritionflag\"})\n",
    "\n",
    "last_date.to_csv('attritionflags.csv') # Should have (3214771, 4)\n",
    "\n",
    "### Create Target Flag \n",
    "\n",
    "accts.DATE_KEY.unique()\n",
    "accts.shape, accts.head()\n",
    "\n",
    "attrition_flag = pd.read_csv('attritionflags.csv')\n",
    "\n",
    "# Load accts and attrition flag file before \n",
    "\n",
    "def target_func2(for_month,months,rate):         ### rate =1 for target rate , rate anything other than 1 will output the file\n",
    "    acct = accts[accts['DATE_KEY']== for_month]\n",
    "    \n",
    "    for_date = datetime.datetime.strptime(for_month, date_format)\n",
    "    month = for_date.month\n",
    "    file_month = month\n",
    "    year = for_date.year + month // 12\n",
    "    month = month % 12 + 1\n",
    "    day = max(1, calendar.monthrange(year,month)[1])\n",
    "    \n",
    "    last_month = datetime.datetime(year,month,day,0,0,0)\n",
    "    last_month = last_month.strftime('%d%b%Y').upper()\n",
    "    \n",
    "    attrition = attrition_flag[attrition_flag['attritionflag']==1]\n",
    "    attrition = attrition[attrition['lastdate']==last_month]\n",
    "    file = pd.merge(acct,\n",
    "                   attrition,\n",
    "                   left_on = 'I_REC_KEY',\n",
    "                   right_on = 'I_REC_KEY',\n",
    "                   how = 'left')\n",
    "    target = [] \n",
    "    for value in file[\"attritionflag\"]: \n",
    "        if value == 1: \n",
    "            target.append(1) \n",
    "        else: \n",
    "            target.append(0) \n",
    "    file['target']=target\n",
    "    file['month']=file_month\n",
    "    file = file.drop(columns=['lastdate','lastdateindate','attritionflag'],axis=1)\n",
    "    \n",
    "    target_rate = file[file['target']==1].shape[0]/file.shape[0]\n",
    "    if rate == 1: \n",
    "        return target_rate \n",
    "    else: \n",
    "        return file\n",
    "\n",
    "nov_file = target_func2('30NOV2018',1,0)\n",
    "dec_file = target_func2('31DEC2018',1,0)\n",
    "jan_file = target_func2('31JAN2019',1,0)\n",
    "feb_file = target_func2('28FEB2019',1,0)\n",
    "mar_file = target_func2('31MAR2019',1,0)\n",
    "apr_file = target_func2('30APR2019',1,0)\n",
    "may_file = target_func2('31MAY2019',1,0)\n",
    "jun_file = target_func2('30JUN2019',1,0)\n",
    "jul_file = target_func2('31JUL2019',1,0)\n",
    "aug_file = target_func2('31AUG2019',1,0)\n",
    "sep_file = target_func2('30SEP2019',1,0)\n",
    "oct_file = target_func2('31OCT2019',1,0)\n",
    "\n",
    "df = nov_file.append([dec_file, jan_file,feb_file,mar_file,apr_file,may_file,jun_file,jul_file,aug_file,sep_file,oct_file])\n",
    "\n",
    "## Sampling and building final dataframe\n",
    "\n",
    "final_df = pd.DataFrame(columns=['I_REC_KEY','DATE_KEY','target','month'])\n",
    "\n",
    "for i in range(1,13):\n",
    "    if i == 1:\n",
    "        sam_key = (df[df['month']==i]).sample(250000)\n",
    "        final_df = final_df.append(sam_key)\n",
    "    else:\n",
    "        df_temp = df[df['month']==i]\n",
    "        sam_key = df_temp[~df_temp.I_REC_KEY.isin(final_df['I_REC_KEY'])].sample(250000)\n",
    "        final_df = final_df.append(sam_key)\n",
    "\n",
    "final_df.to_csv('Finaldata_4_EDA.csv')\n",
    "\n",
    "The Data is prepared for EDA now import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter base data for training model and create derived variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I_REC_KEY</th>\n",
       "      <th>target</th>\n",
       "      <th>obs_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141650292</td>\n",
       "      <td>0</td>\n",
       "      <td>31JAN2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47743555</td>\n",
       "      <td>0</td>\n",
       "      <td>31JAN2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150557313</td>\n",
       "      <td>0</td>\n",
       "      <td>31JAN2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10480411</td>\n",
       "      <td>0</td>\n",
       "      <td>31JAN2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127664122</td>\n",
       "      <td>0</td>\n",
       "      <td>31JAN2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I_REC_KEY  target   obs_date\n",
       "0  141650292       0  31JAN2019\n",
       "1   47743555       0  31JAN2019\n",
       "2  150557313       0  31JAN2019\n",
       "3   10480411       0  31JAN2019\n",
       "4  127664122       0  31JAN2019"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the sampled file for 3 columns:I_REC_KEY and obs_date and target\n",
    "# create a list of sampled keys\n",
    "\n",
    "EDA=pd.read_csv('Finaldata_4_EDA.csv',usecols=['I_REC_KEY','obs_date','target'])\n",
    "keys=EDA.I_REC_KEY.unique().tolist()\n",
    "EDA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480769\n",
      "(31357764, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCT_KEY</th>\n",
       "      <th>I_REC_KEY</th>\n",
       "      <th>DATE_KEY</th>\n",
       "      <th>ACH_IN_MTD_AMT</th>\n",
       "      <th>ACH_IN_MTD_QTY</th>\n",
       "      <th>ACH_OUT_MTD_AMT</th>\n",
       "      <th>ACH_OUT_MTD_QTY</th>\n",
       "      <th>CHECK_CASHING_MTD_AMT</th>\n",
       "      <th>CHECK_CASHING_MTD_QTY</th>\n",
       "      <th>CHK_WRITTEN_MTD_AMT</th>\n",
       "      <th>CHK_WRITTEN_MTD_QTY</th>\n",
       "      <th>DEBIT_CARD_MTD_AMT</th>\n",
       "      <th>DEBIT_CARD_MTD_QTY</th>\n",
       "      <th>MOBILE_IMD_DEP_AMT</th>\n",
       "      <th>MOBILE_IMD_DEP_QTY</th>\n",
       "      <th>MOBILE_STD_DEP_AMT</th>\n",
       "      <th>MOBILE_STD_DEP_QTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3683895</td>\n",
       "      <td>9023693</td>\n",
       "      <td>31OCT2018</td>\n",
       "      <td>5392.35</td>\n",
       "      <td>2</td>\n",
       "      <td>352.61</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>258.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2223868</td>\n",
       "      <td>9035845</td>\n",
       "      <td>31OCT2018</td>\n",
       "      <td>6205.11</td>\n",
       "      <td>4</td>\n",
       "      <td>67.93</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>223.75</td>\n",
       "      <td>3</td>\n",
       "      <td>1593.74</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3400641</td>\n",
       "      <td>9676268</td>\n",
       "      <td>31OCT2018</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4205.93</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500.00</td>\n",
       "      <td>1</td>\n",
       "      <td>350.04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2599780</td>\n",
       "      <td>9350982</td>\n",
       "      <td>31OCT2018</td>\n",
       "      <td>5130.46</td>\n",
       "      <td>3</td>\n",
       "      <td>8341.19</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>2</td>\n",
       "      <td>3144.60</td>\n",
       "      <td>73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3624223</td>\n",
       "      <td>9036014</td>\n",
       "      <td>31OCT2018</td>\n",
       "      <td>1517.64</td>\n",
       "      <td>2</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>339.06</td>\n",
       "      <td>3</td>\n",
       "      <td>555.03</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACCT_KEY  I_REC_KEY   DATE_KEY  ACH_IN_MTD_AMT  ACH_IN_MTD_QTY  \\\n",
       "1   3683895    9023693  31OCT2018         5392.35               2   \n",
       "2   2223868    9035845  31OCT2018         6205.11               4   \n",
       "3   3400641    9676268  31OCT2018            0.00               0   \n",
       "4   2599780    9350982  31OCT2018         5130.46               3   \n",
       "5   3624223    9036014  31OCT2018         1517.64               2   \n",
       "\n",
       "   ACH_OUT_MTD_AMT  ACH_OUT_MTD_QTY  CHECK_CASHING_MTD_AMT  \\\n",
       "1           352.61                4                    0.0   \n",
       "2            67.93                2                    0.0   \n",
       "3          4205.93                4                    0.0   \n",
       "4          8341.19               17                    0.0   \n",
       "5             6.00                1                    0.0   \n",
       "\n",
       "   CHECK_CASHING_MTD_QTY  CHK_WRITTEN_MTD_AMT  CHK_WRITTEN_MTD_QTY  \\\n",
       "1                      0               258.00                    1   \n",
       "2                      0               223.75                    3   \n",
       "3                      0              2500.00                    1   \n",
       "4                      0              1200.00                    2   \n",
       "5                      0               339.06                    3   \n",
       "\n",
       "   DEBIT_CARD_MTD_AMT  DEBIT_CARD_MTD_QTY  MOBILE_IMD_DEP_AMT  \\\n",
       "1                0.00                   0                 0.0   \n",
       "2             1593.74                   2                 0.0   \n",
       "3              350.04                   3                 0.0   \n",
       "4             3144.60                  73                 0.0   \n",
       "5              555.03                  14                 0.0   \n",
       "\n",
       "   MOBILE_IMD_DEP_QTY  MOBILE_STD_DEP_AMT  MOBILE_STD_DEP_QTY  \n",
       "1                   0                 0.0                   0  \n",
       "2                   0                 0.0                   0  \n",
       "3                   0                 0.0                   0  \n",
       "4                   0              2300.0                   3  \n",
       "5                   0                 0.0                   0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter tran_summ for keys from the merged file\n",
    "\n",
    "df_sample = pd.read_table('UC_CoBA_TRAN_SUMM_MONTHLY_15.txt', nrows=10)\n",
    "df_sample_size = df_sample.memory_usage(index=True).sum()\n",
    "\n",
    "my_chunk = (1000000000 / df_sample_size)/10\n",
    "my_chunk = int(my_chunk//1) # we get the integer part\n",
    "print (my_chunk)\n",
    "\n",
    "df_chunk = pd.read_csv('UC_CoBA_TRAN_SUMM_MONTHLY_15.txt', chunksize=my_chunk,sep=\"|\")\n",
    "chunk_list = []  # append each chunk df here\n",
    " \n",
    "# Each chunk is in df format\n",
    "for chunk in df_chunk: \n",
    "    # perform data filtering\n",
    "    chunk_filter = chunk[chunk['I_REC_KEY'].isin(keys)]\n",
    "   \n",
    "    # Once the data filtering is done, append the chunk to list\n",
    "    chunk_list.append(chunk_filter)\n",
    "   \n",
    "# concat the list into dataframe\n",
    "tran = pd.concat(chunk_list)\n",
    "\n",
    "print(tran.shape)\n",
    "tran.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tran.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge on tran_summ with sampled file\n",
    "tran_eda=pd.merge(tran,EDA[['I_REC_KEY','obs_date','target']],on=['I_REC_KEY'])\n",
    "tran_eda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert obs date and tran date to date type and sort the table by I_REC_KEY and tran date\n",
    "tran_eda['DATE']=pd.to_datetime(tran_eda.DATE_KEY)\n",
    "tran_eda['obs_date2']=pd.to_datetime(tran_eda.obs_date)\n",
    "tran_eda=tran_eda.sort_values(['I_REC_KEY','DATE'])\n",
    "print(tran_eda.shape)\n",
    "#tran_eda.to_csv('tran_target.txt',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create New variables in Transaction summary file\n",
    "% difference of amount ($) with last month for each account<br>\n",
    "difference between number of swipes with last month for each account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new variables - % diff of Amount and diff of Quantity\n",
    "\n",
    "#ACH_IN\n",
    "%timeit tran_eda['%diff_ACH_IN']=tran_eda.groupby(['ACCT_KEY']).ACH_IN_MTD_AMT.pct_change().replace((np.inf,-np.inf,np.nan), 0)\n",
    "tran_eda['diff_ACH_IN_QTY']=tran_eda.groupby(['ACCT_KEY']).ACH_IN_MTD_QTY.diff().replace((np.inf,-np.inf,np.nan), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACH_OUT\n",
    "%timeit tran_eda['%diff_ACH_OUT']=tran_eda.groupby(['ACCT_KEY']).ACH_OUT_MTD_AMT.pct_change().replace((np.inf,-np.inf,np.nan), 0)\n",
    "tran_eda['diff_ACH_OUT_QTY']=tran_eda.groupby(['ACCT_KEY']).ACH_OUT_MTD_QTY.diff().replace((np.inf,-np.inf,np.nan), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK_CASHING\n",
    "%timeit tran_eda['%diff_CHECK_CASHING']=tran_eda.groupby(['ACCT_KEY']).CHECK_CASHING_MTD_AMT.pct_change().replace((np.inf,-np.inf,np.nan), 0)\n",
    "tran_eda['diff_CHECK_CASHING_QTY']=tran_eda.groupby(['ACCT_KEY']).CHECK_CASHING_MTD_QTY.diff().replace((np.inf,-np.inf,np.nan), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK_WRITTEN\n",
    "%timeit tran_eda['%diff_CHECK_WRITTEN']=tran_eda.groupby(['ACCT_KEY']).CHK_WRITTEN_MTD_AMT.pct_change().replace((np.inf,-np.inf,np.nan), 0)\n",
    "tran_eda['diff_CHECK_WRITTEN']=tran_eda.groupby(['ACCT_KEY']).CHK_WRITTEN_MTD_QTY.diff().replace((np.inf,-np.inf,np.nan), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEBIT_CARD\n",
    "%timeit tran_eda['%diff_DEBIT_CARD']=tran_eda.groupby(['ACCT_KEY']).DEBIT_CARD_MTD_AMT.pct_change().replace((np.inf,-np.inf,np.nan), 0)\n",
    "tran_eda['diff_DEBIT_CARD_QTY']=tran_eda.groupby(['ACCT_KEY']).DEBIT_CARD_MTD_QTY.diff().replace((np.inf,-np.inf,np.nan), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check written per trans, Debit swipe per trans\n",
    "%timeit tran_eda['CHK_WRITTEN_per_trans']=tran_eda['CHK_WRITTEN_MTD_AMT'].div(tran['CHK_WRITTEN_MTD_QTY']).replace((np.inf,-np.inf,np.nan), 0)\n",
    "tran_eda['DEBIT_CARD_per_trans']=tran_eda['DEBIT_CARD_MTD_AMT'].div(tran['DEBIT_CARD_MTD_QTY']).replace((np.inf,-np.inf,np.nan), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_eda.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tran_eda.shape)\n",
    "tran_eda.to_csv('Trans_derived_var.txt',header=True,index=False)\n",
    "tran_eda.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create variable for number of inactive months "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a flag column to get last tran date such that obs date>=tran date\n",
    "tran_eda['date_flag'] = np.where(tran_eda['obs_date2']>=tran_eda['DATE'], 1, 0)\n",
    "\n",
    "#Filter the flagged observations\n",
    "tran_eda=tran_eda[tran_eda.date_flag==1]\n",
    "print(tran_eda.shape)\n",
    "tran_flag1=tran_eda\n",
    "tran_eda.head(12)\n",
    "#tran_eda= all derived columns\n",
    "#tran_flag= all flag = 1 with derived columns\n",
    "#tran_max_date= only max dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the latest flagged tran date for each observation\n",
    "tran_max_date=tran_flag1[['I_REC_KEY','DATE']].groupby('I_REC_KEY').tail(1)\n",
    "tran_max_date.rename(columns={'DATE':'last_tran_date'}, inplace=True)\n",
    "#tran_date.head(10)\n",
    "tran_inact=pd.merge(tran_max_date,tran_flag1,left_on=['I_REC_KEY','last_tran_date'],right_on=['I_REC_KEY','DATE'])\n",
    "print(tran_inact.shape)\n",
    "tran_inact.head()\n",
    "tran_inact['inactive_months']=((tran_inact['obs_date2']-tran_inact['last_tran_date'])/np.timedelta64(1, 'M')).astype(int)\n",
    "tran_inact.inactive_months.value_counts()\n",
    "#tran_inact.to_csv('tran_inactive_months.txt',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_inact.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_inact.to_csv('tran_inactive_months.txt',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_inact.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new variables in accounts file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_table('UC_CoBA_NJB/UC_CoBA_ACCT_BAL_MONTHLY_15.txt', nrows=10)\n",
    "df_sample_size = df_sample.memory_usage(index=True).sum()\n",
    "\n",
    "my_chunk = (1000000000 / df_sample_size)/10\n",
    "my_chunk = int(my_chunk//1) # we get the integer part\n",
    "print (my_chunk)\n",
    "\n",
    "df_chunk = pd.read_csv('UC_CoBA_ACCT_BAL_MONTHLY_15.txt', chunksize=my_chunk,sep=\"|\")\n",
    "chunk_list = []  # append each chunk df here\n",
    " \n",
    "# Each chunk is in df format\n",
    "for chunk in df_chunk: \n",
    "    # perform data filtering\n",
    "    chunk_filter = chunk[chunk['I_REC_KEY'].isin(keys)]\n",
    "   \n",
    "    # Once the data filtering is done, append the chunk to list\n",
    "    chunk_list.append(chunk_filter)\n",
    "   \n",
    "# concat the list into dataframe\n",
    "acct_bal = pd.concat(chunk_list)\n",
    "\n",
    "acct_bal.drop(['MRKTG_PROD_NAME'],axis=1,inplace=True)\n",
    "\n",
    "#from datetime import datetime\n",
    "#acct_bal['DATE']=pd.to_datetime(acct_bal.DATE_KEY)\n",
    "\n",
    "print(acct_bal.shape)\n",
    "print(acct_bal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "acct_bal['DATE']=pd.to_datetime(acct_bal.DATE_KEY)\n",
    "acct_bal=acct_bal.sort_values(by=['I_REC_KEY','DATE'])\n",
    "\n",
    "#ACH_IN\n",
    "acct_bal['%diff_AVG_MONTHLY_BAL']=acct_bal.groupby(['I_REC_KEY']).AVG_MONTHLY_BAL_AMT.pct_change().replace((np.inf,-np.inf,np.nan), 0)\n",
    "acct_bal['%diff_LAST_STMT_BAL']=acct_bal.groupby(['I_REC_KEY']).LAST_STMT_BAL_AMT.pct_change().replace((np.inf,-np.inf,np.nan), 0)\n",
    "acct_bal.drop(['DATE'],1,inplace=True)\n",
    "\n",
    "acct_bal.to_csv('acct_bal_derv.txt',header=True,index=False)\n",
    "print(acct_bal.shape)\n",
    "print(acct_bal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acct_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acct_bal=pd.read_csv('acct_bal_derv.txt',header=0,sep=',')\n",
    "acct_bal.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read customer summary file\n",
    "#### Merge customer and account summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge cust_sum and acct_bal files and write it as .txt file\n",
    "\n",
    "#acct_bal=pd.read_csv('acct_bal_derv.txt',header=0,sep=',')\n",
    "cust_sum=pd.read_csv('cust_summ_train.csv',header=0,sep=',')\n",
    "cust_acct=pd.merge(cust_sum,acct_bal,on=['I_REC_KEY','DATE_KEY'])\n",
    "#tran_acct.to_csv('Tran_acct.txt',header=True,index=False)\n",
    "print(cust_acct.shape)\n",
    "\n",
    "# Acct + Cust = 2888810 rows ~ 2.8 million rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cust_sum=pd.read_csv('cust_summ_train.csv',header=0,sep=',',nrows=10)\n",
    "cust_sum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_acct.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge transaction summary with customer and accounts summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge tran_acct and cust_summ_train files and write it as .txt file\n",
    "\n",
    "#tran_inact=pd.read_csv('last_derv_inact.txt',header=0,sep=',')\n",
    "tran_inact.drop(['last_tran_date', 'target', 'DATE','obs_date', 'obs_date2','date_flag','DATE_KEY'],1,inplace=True)\n",
    "tran_cust=pd.merge(tran_inact,cust_acct,on=['I_REC_KEY'])\n",
    "\n",
    "print(tran_cust.shape)\n",
    "\n",
    "#Acct + Cust =  2888810 rows ~ 2.8 million rows\n",
    "#Tran + Acct + Cust = 2502978 ~ 2.5 million rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_cust.inactive_months.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_cust=tran_cust.replace((np.inf,-np.inf,np.nan), 0)\n",
    "tran_cust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_cust.to_csv('Tran_cust.txt',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers - top and bottom 1 percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change List\n",
    "donotchange = ['ACCT_KEY', 'I_REC_KEY', 'CUST_KEY','DATE_KEY', 'obs_date',\n",
    "               'OLDEST_OPEN_DATE','BRANCH_NBR', 'AFFIL_NBR','IXI_CLUSTER_CODE','HH_KEY','target'\n",
    "               ,'inactive_months']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Numerical columns\n",
    "tran_cust_n1 = tran_cust.select_dtypes([np.number]) #.columns.to_list()\n",
    "tran_cust_n2 = tran_cust_n1.columns\n",
    "num_cols = list(tran_cust_n2)\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Capping and Flooring\n",
    "num_cols2 = list(set(num_cols).difference(donotchange))\n",
    "num_cols2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols2:\n",
    "        percentiles = tran_cust_out[col].quantile([0.01,0.99]).values\n",
    "        tran_cust_out[col] = np.clip(tran_cust_out[col], percentiles[0], percentiles[1])\n",
    "        \n",
    "# Try1 - 1% and 99%\n",
    "# Try2 - 5% and 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier treatment\n",
    "tran_cust_out=tran_cust\n",
    "for col in num_cols:\n",
    "    percentiles = tran_cust_out[col].quantile([0.00,0.99]).values\n",
    "    tran_cust_out[col] = np.clip(tran_cust_out[col], percentiles[0], percentiles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2502958, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACH_IN_MTD_AMT</th>\n",
       "      <th>ACH_IN_MTD_QTY</th>\n",
       "      <th>ACH_OUT_MTD_AMT</th>\n",
       "      <th>ACH_OUT_MTD_QTY</th>\n",
       "      <th>CHK_WRITTEN_MTD_QTY</th>\n",
       "      <th>DEBIT_CARD_MTD_AMT</th>\n",
       "      <th>DEBIT_CARD_MTD_QTY</th>\n",
       "      <th>MOBILE_STD_DEP_QTY</th>\n",
       "      <th>%diff_ACH_IN</th>\n",
       "      <th>diff_ACH_IN_QTY</th>\n",
       "      <th>...</th>\n",
       "      <th>CHECKING_BAL_AMT</th>\n",
       "      <th>CREDIT_CARD_BAL_AMT</th>\n",
       "      <th>OLDEST_OPEN_DATE</th>\n",
       "      <th>LAST_DIRECT_DEPOSIT_AMT</th>\n",
       "      <th>target</th>\n",
       "      <th>AVG_MONTHLY_BAL_AMT</th>\n",
       "      <th>LAST_STMT_BAL_AMT</th>\n",
       "      <th>%diff_AVG_MONTHLY_BAL</th>\n",
       "      <th>%diff_LAST_STMT_BAL</th>\n",
       "      <th>recency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>678.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>1973-07-01</td>\n",
       "      <td>4116.0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.797251</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1772.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>418.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3273.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1991-11-21</td>\n",
       "      <td>443.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3273.0</td>\n",
       "      <td>3225.0</td>\n",
       "      <td>-0.255967</td>\n",
       "      <td>-0.106648</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7004.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.448873</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5673.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1991-10-20</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4164.0</td>\n",
       "      <td>4678.0</td>\n",
       "      <td>-0.370045</td>\n",
       "      <td>-0.516985</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3897.19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.110022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2244.0</td>\n",
       "      <td>3671.0</td>\n",
       "      <td>1991-11-07</td>\n",
       "      <td>647.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2244.0</td>\n",
       "      <td>4191.0</td>\n",
       "      <td>0.909787</td>\n",
       "      <td>2.498331</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7662.69</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2309.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1991-08-30</td>\n",
       "      <td>5284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>7704.0</td>\n",
       "      <td>0.730970</td>\n",
       "      <td>0.500292</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACH_IN_MTD_AMT  ACH_IN_MTD_QTY  ACH_OUT_MTD_AMT  ACH_OUT_MTD_QTY  \\\n",
       "0         1000.00             1.0              0.0              0.0   \n",
       "1         1772.00             4.0              2.0              2.0   \n",
       "2         7004.02             3.0              0.0              0.0   \n",
       "3         3897.19             4.0              0.0              0.0   \n",
       "4         7662.69             2.0           2309.6              5.0   \n",
       "\n",
       "   CHK_WRITTEN_MTD_QTY  DEBIT_CARD_MTD_AMT  DEBIT_CARD_MTD_QTY  \\\n",
       "0                  0.0                0.00                 0.0   \n",
       "1                  2.0              418.99                 1.0   \n",
       "2                  5.0                0.00                 0.0   \n",
       "3                 10.0                0.00                 0.0   \n",
       "4                  1.0                0.00                 0.0   \n",
       "\n",
       "   MOBILE_STD_DEP_QTY  %diff_ACH_IN  diff_ACH_IN_QTY  ...  CHECKING_BAL_AMT  \\\n",
       "0                 0.0      0.000000              0.0  ...             678.0   \n",
       "1                 0.0      0.000000              0.0  ...            3273.0   \n",
       "2                 0.0     -0.448873             -1.0  ...            5673.0   \n",
       "3                 0.0      1.110022              1.0  ...            2244.0   \n",
       "4                 0.0      0.450528              1.0  ...            6299.0   \n",
       "\n",
       "   CREDIT_CARD_BAL_AMT  OLDEST_OPEN_DATE  LAST_DIRECT_DEPOSIT_AMT  target  \\\n",
       "0                896.0        1973-07-01                   4116.0       0   \n",
       "1                  0.0        1991-11-21                    443.0       0   \n",
       "2                  0.0        1991-10-20                   3388.0       0   \n",
       "3               3671.0        1991-11-07                    647.0       0   \n",
       "4                  0.0        1991-08-30                   5284.0       0   \n",
       "\n",
       "   AVG_MONTHLY_BAL_AMT  LAST_STMT_BAL_AMT  %diff_AVG_MONTHLY_BAL  \\\n",
       "0                 59.0               -2.0              -0.797251   \n",
       "1               3273.0             3225.0              -0.255967   \n",
       "2               4164.0             4678.0              -0.370045   \n",
       "3               2244.0             4191.0               0.909787   \n",
       "4               6299.0             7704.0               0.730970   \n",
       "\n",
       "   %diff_LAST_STMT_BAL  recency  \n",
       "0            -1.250000      553  \n",
       "1            -0.106648      334  \n",
       "2            -0.516985      331  \n",
       "3             2.498331      325  \n",
       "4             0.500292      336  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_cust_out=pd.read_csv('capnfloor_acct_cust_L1U99.txt',header=0,sep=',')\n",
    "tran_cust_out.drop(['Unnamed: 0'],1,inplace=True)\n",
    "print(tran_cust_out.inactive_months.value_counts())\n",
    "print(tran_cust_out.target.value_counts())\n",
    "tran_cust_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_cust_out.describe().to_csv('tran_cust_summary_stats.csv',header=True)\n",
    "tran_cust_out.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot encoding for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping raw variables to check feature importance\n",
    "tran_cust_d=tran_cust_out.drop(['ACH_IN_MTD_AMT', 'ACH_IN_MTD_QTY','ACH_OUT_MTD_AMT', 'ACH_OUT_MTD_QTY', 'CHECK_CASHING_MTD_AMT',\n",
    "                         'CHECK_CASHING_MTD_QTY','CHK_WRITTEN_MTD_AMT', 'CHK_WRITTEN_MTD_QTY','DEBIT_CARD_MTD_AMT',\n",
    "                        'DEBIT_CARD_MTD_QTY', 'AVG_MONTHLY_BAL_AMT', 'LAST_STMT_BAL_AMT'], axis=1)\n",
    "\n",
    "tran_cust_d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ACH_IN_MTD_AMT', 'ACH_IN_MTD_QTY', 'ACH_OUT_MTD_AMT',\n",
       "       'ACH_OUT_MTD_QTY', 'CHK_WRITTEN_MTD_QTY', 'DEBIT_CARD_MTD_AMT',\n",
       "       'DEBIT_CARD_MTD_QTY', 'MOBILE_STD_DEP_QTY', '%diff_ACH_IN',\n",
       "       'diff_ACH_IN_QTY', '%diff_ACH_OUT', '%diff_CHECK_WRITTEN',\n",
       "       'diff_CHECK_WRITTEN', '%diff_DEBIT_CARD', 'diff_DEBIT_CARD_QTY',\n",
       "       'CHK_WRITTEN_per_trans', 'inactive_months', 'CONS_LOAN_BAL_AMT',\n",
       "       'CONS_LOAN_WAR_PCT', 'CONS_DEPOSIT_ACCT_QTY', 'CONS_DEPOSIT_BAL_AMT',\n",
       "       'MORTGAGE_BAL_AMT', 'SAVINGS_BAL_AMT', 'CHECKING_BAL_AMT',\n",
       "       'CREDIT_CARD_BAL_AMT', 'LAST_DIRECT_DEPOSIT_AMT', 'target',\n",
       "       'AVG_MONTHLY_BAL_AMT', 'LAST_STMT_BAL_AMT', '%diff_AVG_MONTHLY_BAL',\n",
       "       '%diff_LAST_STMT_BAL', 'recency', 'DIRECT_DEP_IND_Y',\n",
       "       'ACTIVE_CHK_IND_Y', 'HABITUAL_OD_IND_Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy = pd.get_dummies(tran_cust_out, drop_first=True)\n",
    "df_dummy.columns\n",
    "\n",
    "df_dummy.to_csv('capfloor/recency/tran_cust_dummies.txt',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy=pd.read_csv('capfloor/tran_cust_dummies.txt',header=0,sep=\",\")\n",
    "df_dummy.drop('Unnamed: 0',1,inplace=True)\n",
    "print(df_dummy.shape)\n",
    "df_dummy.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Information Value of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Information Value\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas.core.algorithms as algos\n",
    "from pandas import Series\n",
    "import scipy.stats.stats as stats\n",
    "import re\n",
    "import traceback\n",
    "import string\n",
    "\n",
    "max_bin = 20\n",
    "force_bin = 20\n",
    "\n",
    "# define a binning function\n",
    "def mono_bin(Y, X, n = max_bin):\n",
    "    \n",
    "    df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
    "    justmiss = df1[['X','Y']][df1.X.isnull()]\n",
    "    notmiss = df1[['X','Y']][df1.X.notnull()]\n",
    "    r = 0\n",
    "    while np.abs(r) < 1:\n",
    "        try:\n",
    "            d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.qcut(notmiss.X, n)})\n",
    "            d2 = d1.groupby('Bucket', as_index=True)\n",
    "            r, p = stats.spearmanr(d2.mean().X, d2.mean().Y)\n",
    "            n = n - 1 \n",
    "        except Exception as e:\n",
    "            n = n - 1\n",
    "\n",
    "    if len(d2) == 1:\n",
    "        n = force_bin         \n",
    "        bins = algos.quantile(notmiss.X, np.linspace(0, 1, n))\n",
    "        d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.cut(notmiss.X, np.unique(bins),include_lowest=True)}) \n",
    "        d2 = d1.groupby('Bucket', as_index=True)\n",
    "    \n",
    "    d3 = pd.DataFrame({},index=[])\n",
    "    d3[\"MIN_VALUE\"] = d2.min().X\n",
    "    d3[\"MAX_VALUE\"] = d2.max().X\n",
    "    d3[\"COUNT\"] = d2.count().Y\n",
    "    d3[\"EVENT\"] = d2.sum().Y\n",
    "    d3[\"NONEVENT\"] = d2.count().Y - d2.sum().Y\n",
    "    d3=d3.reset_index(drop=True)\n",
    "    \n",
    "    if len(justmiss.index) > 0:\n",
    "        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
    "        d4[\"MAX_VALUE\"] = np.nan\n",
    "        d4[\"COUNT\"] = justmiss.count().Y\n",
    "        d4[\"EVENT\"] = justmiss.sum().Y\n",
    "        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
    "        d3 = d3.append(d4,ignore_index=True)\n",
    "    \n",
    "    d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n",
    "    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n",
    "    d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n",
    "    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n",
    "    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"VAR_NAME\"] = \"VAR\"\n",
    "    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]       \n",
    "    d3 = d3.replace([np.inf, -np.inf], 0)\n",
    "    d3.IV = d3.IV.sum()\n",
    "    \n",
    "    return(d3)\n",
    "\n",
    "def char_bin(Y, X):\n",
    "        \n",
    "    df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
    "    justmiss = df1[['X','Y']][df1.X.isnull()]\n",
    "    notmiss = df1[['X','Y']][df1.X.notnull()]    \n",
    "    df2 = notmiss.groupby('X',as_index=True)\n",
    "    \n",
    "    d3 = pd.DataFrame({},index=[])\n",
    "    d3[\"COUNT\"] = df2.count().Y\n",
    "    d3[\"MIN_VALUE\"] = df2.sum().Y.index\n",
    "    d3[\"MAX_VALUE\"] = d3[\"MIN_VALUE\"]\n",
    "    d3[\"EVENT\"] = df2.sum().Y\n",
    "    d3[\"NONEVENT\"] = df2.count().Y - df2.sum().Y\n",
    "    \n",
    "    if len(justmiss.index) > 0:\n",
    "        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
    "        d4[\"MAX_VALUE\"] = np.nan\n",
    "        d4[\"COUNT\"] = justmiss.count().Y\n",
    "        d4[\"EVENT\"] = justmiss.sum().Y\n",
    "        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
    "        d3 = d3.append(d4,ignore_index=True)\n",
    "    \n",
    "    d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n",
    "    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n",
    "    d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n",
    "    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n",
    "    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"VAR_NAME\"] = \"VAR\"\n",
    "    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]      \n",
    "    d3 = d3.replace([np.inf, -np.inf], 0)\n",
    "    d3.IV = d3.IV.sum()\n",
    "    d3 = d3.reset_index(drop=True)\n",
    "    \n",
    "    return(d3)\n",
    "\n",
    "def data_vars(df1, target):\n",
    "    \n",
    "    stack = traceback.extract_stack()\n",
    "    filename, lineno, function_name, code = stack[-2]\n",
    "    vars_name = re.compile(r'\\((.*?)\\).*$').search(code).groups()[0]\n",
    "    final = (re.findall(r\"[\\w']+\", vars_name))[-1]\n",
    "    \n",
    "    x = df1.dtypes.index\n",
    "    count = -1\n",
    "    \n",
    "    for i in x:\n",
    "        if i.upper() not in (final.upper()):\n",
    "            if np.issubdtype(df1[i], np.number) and len(Series.unique(df1[i])) > 2:\n",
    "                conv = mono_bin(target, df1[i])\n",
    "                conv[\"VAR_NAME\"] = i\n",
    "                count = count + 1\n",
    "            else:\n",
    "                conv = char_bin(target, df1[i])\n",
    "                conv[\"VAR_NAME\"] = i            \n",
    "                count = count + 1\n",
    "                \n",
    "            if count == 0:\n",
    "                iv_df = conv\n",
    "            else:\n",
    "                iv_df = iv_df.append(conv,ignore_index=True)\n",
    "    \n",
    "    iv = pd.DataFrame({'IV':iv_df.groupby('VAR_NAME').IV.max()})\n",
    "    iv = iv.reset_index()\n",
    "    return(iv_df,iv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find correlation among Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation for continuous variables\n",
    "corr=tran_cust_n.corr()\n",
    "corr_tran=corr['target'].sort_values()\n",
    "print(corr_tran)\n",
    "corr.to_csv('capfloor/corr_tran_cust.csv', index=True, header=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.subplots(figsize=(10,10))\n",
    "chart=sns.heatmap(corr, vmax=0.9, square=True)\n",
    "chart.set_yticklabels(chart.get_yticklabels(), rotation=0)\n",
    "plt.savefig('capfloor/tran_cust_corr.jpg', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d=df_dummy.drop(['target'],1)\n",
    "y_train_d=df_dummy.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR_NAME</th>\n",
       "      <th>MIN_VALUE</th>\n",
       "      <th>MAX_VALUE</th>\n",
       "      <th>COUNT</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>EVENT_RATE</th>\n",
       "      <th>NONEVENT</th>\n",
       "      <th>NON_EVENT_RATE</th>\n",
       "      <th>DIST_EVENT</th>\n",
       "      <th>DIST_NON_EVENT</th>\n",
       "      <th>WOE</th>\n",
       "      <th>IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>CHECKING_BAL_AMT</td>\n",
       "      <td>7436.0</td>\n",
       "      <td>19507.0</td>\n",
       "      <td>278083</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>276963</td>\n",
       "      <td>0.995972</td>\n",
       "      <td>0.037626</td>\n",
       "      <td>0.111986</td>\n",
       "      <td>-1.090691</td>\n",
       "      <td>1.044922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>CHECKING_BAL_AMT</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>278993</td>\n",
       "      <td>15452</td>\n",
       "      <td>0.055385</td>\n",
       "      <td>263541</td>\n",
       "      <td>0.944615</td>\n",
       "      <td>0.519098</td>\n",
       "      <td>0.106559</td>\n",
       "      <td>1.583394</td>\n",
       "      <td>1.044922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>CHECKING_BAL_AMT</td>\n",
       "      <td>3779.0</td>\n",
       "      <td>7435.0</td>\n",
       "      <td>278035</td>\n",
       "      <td>1147</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>276888</td>\n",
       "      <td>0.995875</td>\n",
       "      <td>0.038533</td>\n",
       "      <td>0.111956</td>\n",
       "      <td>-1.066599</td>\n",
       "      <td>1.044922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>CHECKING_BAL_AMT</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>3778.0</td>\n",
       "      <td>278042</td>\n",
       "      <td>1393</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>276649</td>\n",
       "      <td>0.994990</td>\n",
       "      <td>0.046797</td>\n",
       "      <td>0.111859</td>\n",
       "      <td>-0.871426</td>\n",
       "      <td>1.044922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>CHECKING_BAL_AMT</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>2124.0</td>\n",
       "      <td>278006</td>\n",
       "      <td>1828</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>276178</td>\n",
       "      <td>0.993425</td>\n",
       "      <td>0.061410</td>\n",
       "      <td>0.111669</td>\n",
       "      <td>-0.597959</td>\n",
       "      <td>1.044922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>inactive_months</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>101193</td>\n",
       "      <td>2373</td>\n",
       "      <td>0.023450</td>\n",
       "      <td>98820</td>\n",
       "      <td>0.976550</td>\n",
       "      <td>0.079719</td>\n",
       "      <td>0.039956</td>\n",
       "      <td>0.690719</td>\n",
       "      <td>0.029147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>inactive_months</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2401765</td>\n",
       "      <td>27394</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>2374371</td>\n",
       "      <td>0.988594</td>\n",
       "      <td>0.920281</td>\n",
       "      <td>0.960044</td>\n",
       "      <td>-0.042300</td>\n",
       "      <td>0.029147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>MOBILE_STD_DEP_QTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2360210</td>\n",
       "      <td>28993</td>\n",
       "      <td>0.012284</td>\n",
       "      <td>2331217</td>\n",
       "      <td>0.987716</td>\n",
       "      <td>0.973998</td>\n",
       "      <td>0.942595</td>\n",
       "      <td>0.032773</td>\n",
       "      <td>0.027824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>MOBILE_STD_DEP_QTY</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65755</td>\n",
       "      <td>439</td>\n",
       "      <td>0.006676</td>\n",
       "      <td>65316</td>\n",
       "      <td>0.993324</td>\n",
       "      <td>0.014748</td>\n",
       "      <td>0.026410</td>\n",
       "      <td>-0.582629</td>\n",
       "      <td>0.027824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>MOBILE_STD_DEP_QTY</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76993</td>\n",
       "      <td>335</td>\n",
       "      <td>0.004351</td>\n",
       "      <td>76658</td>\n",
       "      <td>0.995649</td>\n",
       "      <td>0.011254</td>\n",
       "      <td>0.030996</td>\n",
       "      <td>-1.013115</td>\n",
       "      <td>0.027824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               VAR_NAME  MIN_VALUE  MAX_VALUE    COUNT  EVENT  EVENT_RATE  \\\n",
       "182    CHECKING_BAL_AMT     7436.0    19507.0   278083   1120    0.004028   \n",
       "175    CHECKING_BAL_AMT      -78.0      115.0   278993  15452    0.055385   \n",
       "181    CHECKING_BAL_AMT     3779.0     7435.0   278035   1147    0.004125   \n",
       "180    CHECKING_BAL_AMT     2125.0     3778.0   278042   1393    0.005010   \n",
       "179    CHECKING_BAL_AMT     1232.0     2124.0   278006   1828    0.006575   \n",
       "..                  ...        ...        ...      ...    ...         ...   \n",
       "139     inactive_months        2.0       11.0   101193   2373    0.023450   \n",
       "138     inactive_months        0.0        1.0  2401765  27394    0.011406   \n",
       "61   MOBILE_STD_DEP_QTY        0.0        1.0  2360210  28993    0.012284   \n",
       "62   MOBILE_STD_DEP_QTY        2.0        2.0    65755    439    0.006676   \n",
       "63   MOBILE_STD_DEP_QTY        3.0        5.0    76993    335    0.004351   \n",
       "\n",
       "     NONEVENT  NON_EVENT_RATE  DIST_EVENT  DIST_NON_EVENT       WOE        IV  \n",
       "182    276963        0.995972    0.037626        0.111986 -1.090691  1.044922  \n",
       "175    263541        0.944615    0.519098        0.106559  1.583394  1.044922  \n",
       "181    276888        0.995875    0.038533        0.111956 -1.066599  1.044922  \n",
       "180    276649        0.994990    0.046797        0.111859 -0.871426  1.044922  \n",
       "179    276178        0.993425    0.061410        0.111669 -0.597959  1.044922  \n",
       "..        ...             ...         ...             ...       ...       ...  \n",
       "139     98820        0.976550    0.079719        0.039956  0.690719  0.029147  \n",
       "138   2374371        0.988594    0.920281        0.960044 -0.042300  0.029147  \n",
       "61    2331217        0.987716    0.973998        0.942595  0.032773  0.027824  \n",
       "62      65316        0.993324    0.014748        0.026410 -0.582629  0.027824  \n",
       "63      76658        0.995649    0.011254        0.030996 -1.013115  0.027824  \n",
       "\n",
       "[231 rows x 12 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_iv, IV = data_vars(X_train_d,y_train_d)\n",
    "final_iv=final_iv.sort_values(['IV'],ascending=False)\n",
    "#final_iv.to_csv('capfloor/Tran_cust_IV.csv',header=True,index=False)\n",
    "final_iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_iv.to_csv('capfloor/recency/Tran_cust_IV.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d=df_dummy.drop(['target','CHECK_CASHING_MTD_AMT','CHECK_CASHING_MTD_QTY','MOBILE_IMD_DEP_AMT','MOBILE_IMD_DEP_QTY',\n",
    "'SAFEBOX_BAL_AMT'],1)\n",
    "y_train_d=df_dummy.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dummy=pd.read_csv('tran_cust_dummies.txt',header=0,sep=',')\n",
    "print(df_dummy.shape)\n",
    "print(df_dummy.columns)\n",
    "df_dummy.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import datetime\n",
    "# check run time of the code\n",
    "start_time=datetime.datetime.now()\n",
    "\n",
    "\n",
    "model_d=RandomForestClassifier()\n",
    "%timeit model_d.fit(X_train_d,y_train_d)\n",
    "print(model_d.get_params())\n",
    "\n",
    "\n",
    "end_time=datetime.datetime.now()\n",
    " \n",
    "diff = end_time - start_time\n",
    " \n",
    "days, seconds = diff.days, diff.seconds\n",
    "hours = days * 24 + seconds // 3600\n",
    "minutes = (seconds % 3600) // 60\n",
    "seconds = seconds % 60\n",
    " \n",
    "print(\"Time between dates: %d hours, %d minutes and %d seconds\" % (hours, minutes, seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance by Random Forest\n",
    "results_rf_d=pd.DataFrame()\n",
    "results_rf_d['Variable']=X_train_d.columns\n",
    "results_rf_d['Importance'] = model_d.feature_importances_\n",
    "results_rf_d.sort_values(by='Importance',ascending=False,inplace=True)\n",
    "results_rf_d.to_csv('capfloor/Random Forest_feature_importance_outliers.csv',header=True,index=False)\n",
    "results_rf_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit XGBoost model on training data\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import datetime\n",
    "# check run time of the code\n",
    "start_time=datetime.datetime.now()\n",
    "print(start_time)\n",
    "\n",
    "model = XGBClassifier()\n",
    "%timeit model.fit(X_train_d, y_train_d)\n",
    "print(model.get_params())\n",
    "\n",
    "\n",
    "end_time=datetime.datetime.now()\n",
    " \n",
    "diff = end_time - start_time\n",
    " \n",
    "days, seconds = diff.days, diff.seconds\n",
    "hours = days * 24 + seconds // 3600\n",
    "minutes = (seconds % 3600) // 60\n",
    "seconds = seconds % 60\n",
    " \n",
    "print(\"Time between dates: %d hours, %d minutes and %d seconds\" % (hours, minutes, seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "XGB=pd.DataFrame()\n",
    "XGB['Variable']=X_train_d.columns\n",
    "XGB['Importances'] = model.feature_importances_\n",
    "XGB.sort_values(by='Importances',ascending=False,inplace=True)\n",
    "XGB.to_csv('capfloor/XGB_feature_importance_outliers.csv',header=True,index=False)\n",
    "XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tran_cust_n.drop('target',axis=1), \n",
    "           tran_cust_n['target'], test_size=0.30, \n",
    "            random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select significant variables resulting from Feature Importance, IV and correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy=pd.read_csv('capfloor/tran_cust_dummies.txt',header=0,sep=',')\n",
    "df_dummy_clean_var=df_dummy[['AVG_MONTHLY_BAL_AMT','CHECKING_BAL_AMT','ACTIVE_CHK_IND_Y','ACH_IN_MTD_AMT',\n",
    "                             'CONS_DEPOSIT_ACCT_QTY','inactive_months','HABITUAL_OD_IND_Y','ACH_IN_MTD_QTY',\n",
    "                             'CHK_WRITTEN_MTD_QTY','CONS_LOAN_BAL_AMT','CONS_DEPOSIT_BAL_AMT','LAST_STMT_BAL_AMT',\n",
    "                             '%diff_AVG_MONTHLY_BAL','SAVINGS_BAL_AMT','MOBILE_STD_DEP_QTY','DIRECT_DEP_IND_Y',\n",
    "                             'DEBIT_CARD_MTD_AMT','ACH_OUT_MTD_QTY','%diff_ACH_IN','diff_ACH_IN_QTY','DEBIT_CARD_MTD_QTY',\n",
    "                             '%diff_LAST_STMT_BAL','CONS_LOAN_WAR_PCT','diff_DEBIT_CARD_QTY','%diff_DEBIT_CARD',\n",
    "                             'LAST_DIRECT_DEPOSIT_AMT','diff_CHECK_WRITTEN','%diff_ACH_OUT','ACH_OUT_MTD_AMT',\n",
    "                             '%diff_CHECK_WRITTEN','MORTGAGE_BAL_AMT','CHK_WRITTEN_per_trans','CREDIT_CARD_BAL_AMT','target'\n",
    "]]\n",
    "\n",
    "df_dummy_clean_var.to_csv('capfloor/tran_cust_dummies_signif_var.txt',header=True,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2502978, 33)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy_clean_var=pd.read_csv('capfloor/tran_cust_dummies_signif_var.txt',header=0,sep=',')\n",
    "\n",
    "X_train=df_dummy_clean_var.drop(['target'],1)\n",
    "y_train=df_dummy_clean_var.target\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG_MONTHLY_BAL_AMT</th>\n",
       "      <th>CHECKING_BAL_AMT</th>\n",
       "      <th>ACTIVE_CHK_IND_Y</th>\n",
       "      <th>ACH_IN_MTD_AMT</th>\n",
       "      <th>CONS_DEPOSIT_ACCT_QTY</th>\n",
       "      <th>inactive_months</th>\n",
       "      <th>HABITUAL_OD_IND_Y</th>\n",
       "      <th>ACH_IN_MTD_QTY</th>\n",
       "      <th>CHK_WRITTEN_MTD_QTY</th>\n",
       "      <th>CONS_LOAN_BAL_AMT</th>\n",
       "      <th>...</th>\n",
       "      <th>diff_DEBIT_CARD_QTY</th>\n",
       "      <th>%diff_DEBIT_CARD</th>\n",
       "      <th>LAST_DIRECT_DEPOSIT_AMT</th>\n",
       "      <th>diff_CHECK_WRITTEN</th>\n",
       "      <th>%diff_ACH_OUT</th>\n",
       "      <th>ACH_OUT_MTD_AMT</th>\n",
       "      <th>%diff_CHECK_WRITTEN</th>\n",
       "      <th>MORTGAGE_BAL_AMT</th>\n",
       "      <th>CHK_WRITTEN_per_trans</th>\n",
       "      <th>CREDIT_CARD_BAL_AMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.0</td>\n",
       "      <td>678.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101589.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72717.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3273.0</td>\n",
       "      <td>3273.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1772.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.983167</td>\n",
       "      <td>443.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4164.0</td>\n",
       "      <td>5673.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7004.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.749441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2244.0</td>\n",
       "      <td>2244.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3897.19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3671.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>647.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.121840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3671.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6299.0</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7662.69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5284.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.487177</td>\n",
       "      <td>2309.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AVG_MONTHLY_BAL_AMT  CHECKING_BAL_AMT  ACTIVE_CHK_IND_Y  ACH_IN_MTD_AMT  \\\n",
       "0                 59.0             678.0                 1         1000.00   \n",
       "1               3273.0            3273.0                 1         1772.00   \n",
       "2               4164.0            5673.0                 1         7004.02   \n",
       "3               2244.0            2244.0                 1         3897.19   \n",
       "4               6299.0            6299.0                 1         7662.69   \n",
       "\n",
       "   CONS_DEPOSIT_ACCT_QTY  inactive_months  HABITUAL_OD_IND_Y  ACH_IN_MTD_QTY  \\\n",
       "0                    3.0                1                  1             1.0   \n",
       "1                    2.0                0                  0             4.0   \n",
       "2                    3.0                0                  0             3.0   \n",
       "3                    2.0                0                  0             4.0   \n",
       "4                    1.0                0                  0             2.0   \n",
       "\n",
       "   CHK_WRITTEN_MTD_QTY  CONS_LOAN_BAL_AMT  ...  diff_DEBIT_CARD_QTY  \\\n",
       "0                  0.0           101589.0  ...                  0.0   \n",
       "1                  2.0                0.0  ...                  0.0   \n",
       "2                  5.0                0.0  ...                  0.0   \n",
       "3                 10.0             3671.0  ...                  0.0   \n",
       "4                  1.0                0.0  ...                  0.0   \n",
       "\n",
       "   %diff_DEBIT_CARD  LAST_DIRECT_DEPOSIT_AMT  diff_CHECK_WRITTEN  \\\n",
       "0          0.000000                   4116.0                 0.0   \n",
       "1          5.983167                    443.0                 2.0   \n",
       "2          0.000000                   3388.0                 2.0   \n",
       "3          0.000000                    647.0                 7.0   \n",
       "4          0.000000                   5284.0                 1.0   \n",
       "\n",
       "   %diff_ACH_OUT  ACH_OUT_MTD_AMT  %diff_CHECK_WRITTEN  MORTGAGE_BAL_AMT  \\\n",
       "0       0.000000              0.0             0.000000           72717.0   \n",
       "1       0.000000              2.0             0.000000               0.0   \n",
       "2       0.000000              0.0            -0.749441               0.0   \n",
       "3       0.000000              0.0             1.121840               0.0   \n",
       "4      -0.487177           2309.6             0.000000               0.0   \n",
       "\n",
       "   CHK_WRITTEN_per_trans  CREDIT_CARD_BAL_AMT  \n",
       "0                    0.0                896.0  \n",
       "1                    0.0                  0.0  \n",
       "2                    0.0                  0.0  \n",
       "3                    0.0               3671.0  \n",
       "4                    0.0                  0.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    98.810737\n",
       "1     1.189263\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy_clean_var['target'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2473211\n",
       "1      29767\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy_clean_var['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersample Data to boost population of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-11 15:12:20.325978\n",
      "Counter({0: 595340, 1: 29767})\n",
      "Time between dates: 0 hours, 0 minutes and 1 seconds\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "# check run time of the code\n",
    "start_time=datetime.datetime.now()\n",
    "print(start_time)\n",
    "\n",
    "\n",
    "# define undersample strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.05, random_state=100)\n",
    "# fit and apply the transform\n",
    "X_under, y_under = undersample.fit_resample(X_train_d, y_train_d)\n",
    "# summarize class distribution\n",
    "print(Counter(y_under))\n",
    "\n",
    "\n",
    "end_time=datetime.datetime.now()\n",
    "\n",
    "diff = end_time - start_time\n",
    "\n",
    "days, seconds = diff.days, diff.seconds\n",
    "hours = days * 24 + seconds // 3600\n",
    "minutes = (seconds % 3600) // 60\n",
    "seconds = seconds % 60\n",
    "\n",
    "print(\"Time between dates: %d hours, %d minutes and %d seconds\" % (hours, minutes, seconds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under.to_csv('capfloor/recency/Random_X_train.txt',header=True,index=False)\n",
    "y_under.to_csv('capfloor/recency/Random_y_train.txt',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(625107,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_under.shape\n",
    "y_under.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 76203, 1: 3810})\n",
      "Counter({0: 519137, 1: 25957})\n",
      "Counter({0: 259568, 1: 12979})\n",
      "Counter({0: 259569, 1: 12978})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(\n",
    "        X_under, y_under,stratify=y_under, test_size=0.872,random_state=100)\n",
    "\n",
    "X_val_1, X_val_2, y_val_1, y_val_2 = train_test_split(\n",
    "        X_test_1, y_test_1, stratify=y_test_1, test_size=0.5,random_state=100)\n",
    "print(Counter(y_train_1))\n",
    "print(Counter(y_test_1))\n",
    "print(Counter(y_val_1))\n",
    "print(Counter(y_val_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1.to_csv('capfloor/recency/X_train.txt',header=True,index=False)\n",
    "y_train_1.to_csv('capfloor/recency/y_train.txt',header=True,index=False)\n",
    "X_test_1.to_csv('capfloor/recency/X_total_val.txt',header=True,index=False)\n",
    "y_test_1.to_csv('capfloor/recency/y_total_val.txt',header=True,index=False)\n",
    "X_val_1.to_csv('capfloor/recency/X_val_1.txt',header=True,index=False)\n",
    "y_val_1.to_csv('capfloor/recency/y_val_1.txt',header=True,index=False)\n",
    "X_val_2.to_csv('capfloor/recency/X_val_2.txt',header=True,index=False)\n",
    "y_val_2.to_csv('capfloor/recency/y_val_2.txt',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set will be used for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
